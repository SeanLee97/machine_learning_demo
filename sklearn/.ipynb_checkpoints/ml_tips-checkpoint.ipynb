{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析常用算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集分为train data, develope data, test data 或（train data, test data）\n",
    "\n",
    "train data 用于模型的训练，其他用于模型的评估\n",
    "模型在训练集和测试集上的结果可以反映拟合情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类问题一般用StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "StratifiedKFold(n_splits=2, random_state=1, shuffle=True)\n",
      "TRAIN: [  0   1   4   5   6   7   8   9  10  11  12  14  15  16  18  20  25  28\n",
      "  30  33  34  37  43  44  47  50  53  54  56  57  58  59  62  65  66  68\n",
      "  71  72  73  74  75  76  82  84  85  91  94  95  98  99 100 102 104 106\n",
      " 107 108 110 111 112 113 116 118 120 121 125 127 128 130 139 140 141 144\n",
      " 147 148 149] TEST: [  2   3  13  17  19  21  22  23  24  26  27  29  31  32  35  36  38  39\n",
      "  40  41  42  45  46  48  49  51  52  55  60  61  63  64  67  69  70  77\n",
      "  78  79  80  81  83  86  87  88  89  90  92  93  96  97 101 103 105 109\n",
      " 114 115 117 119 122 123 124 126 129 131 132 133 134 135 136 137 138 142\n",
      " 143 145 146]\n",
      "TRAIN: [  2   3  13  17  19  21  22  23  24  26  27  29  31  32  35  36  38  39\n",
      "  40  41  42  45  46  48  49  51  52  55  60  61  63  64  67  69  70  77\n",
      "  78  79  80  81  83  86  87  88  89  90  92  93  96  97 101 103 105 109\n",
      " 114 115 117 119 122 123 124 126 129 131 132 133 134 135 136 137 138 142\n",
      " 143 145 146] TEST: [  0   1   4   5   6   7   8   9  10  11  12  14  15  16  18  20  25  28\n",
      "  30  33  34  37  43  44  47  50  53  54  56  57  58  59  62  65  66  68\n",
      "  71  72  73  74  75  76  82  84  85  91  94  95  98  99 100 102 104 106\n",
      " 107 108 110 111 112 113 116 118 120 121 125 127 128 130 139 140 141 144\n",
      " 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "print(skf.get_n_splits(data, target))\n",
    "print(skf)\n",
    "for train_idx, test_idx in skf.split(data, target):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    X_train, X_test = data[train_idx], data[test_idx]\n",
    "    y_train, y_test = target[train_idx], target[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归问题一般用KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "KFold(n_splits=2, random_state=1, shuffle=True)\n",
      "TRAIN: [  0   1   3   7   8   9  10  13  15  20  21  22  23  24  25  26  27  30\n",
      "  32  34  37  38  41  43  47  49  50  52  57  60  61  63  64  67  68  70\n",
      "  71  72  74  76  79  80  81  82  83  86  87  88  89  93  96  97 100 101\n",
      " 105 106 109 111 115 116 121 124 129 130 133 134 136 137 140 142 143 145\n",
      " 147 148 149] TEST: [  2   4   5   6  11  12  14  16  17  18  19  28  29  31  33  35  36  39\n",
      "  40  42  44  45  46  48  51  53  54  55  56  58  59  62  65  66  69  73\n",
      "  75  77  78  84  85  90  91  92  94  95  98  99 102 103 104 107 108 110\n",
      " 112 113 114 117 118 119 120 122 123 125 126 127 128 131 132 135 138 139\n",
      " 141 144 146]\n",
      "TRAIN: [  2   4   5   6  11  12  14  16  17  18  19  28  29  31  33  35  36  39\n",
      "  40  42  44  45  46  48  51  53  54  55  56  58  59  62  65  66  69  73\n",
      "  75  77  78  84  85  90  91  92  94  95  98  99 102 103 104 107 108 110\n",
      " 112 113 114 117 118 119 120 122 123 125 126 127 128 131 132 135 138 139\n",
      " 141 144 146] TEST: [  0   1   3   7   8   9  10  13  15  20  21  22  23  24  25  26  27  30\n",
      "  32  34  37  38  41  43  47  49  50  52  57  60  61  63  64  67  68  70\n",
      "  71  72  74  76  79  80  81  82  83  86  87  88  89  93  96  97 100 101\n",
      " 105 106 109 111 115 116 121 124 129 130 133 134 136 137 140 142 143 145\n",
      " 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "skf = KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "print(skf.get_n_splits(data, target))\n",
    "print(skf)\n",
    "for train_idx, test_idx in skf.split(data, target):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    X_train, X_test = data[train_idx], data[test_idx]\n",
    "    y_train, y_test = target[train_idx], target[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.preprocessing LabelEncoder , OneHotEncoder ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果数据是稠密的可以用numpy的hstack，如果数据是系数的可以用scipy sparse的hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hstack [1 2 3 2 3 4]\n",
      "vstack [[1 2 3]\n",
      " [2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "# numpy.hstack()\n",
    "# 等价于np.concatenate(tup, axis=1)\n",
    "# numpy.vstack()\n",
    "# 等价于np.concatenate(tup, axis=0)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 3, 4])\n",
    "\n",
    "c = np.hstack((a, b))\n",
    "print('hstack', c)\n",
    "c = np.vstack((a, b))\n",
    "print('vstack', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "a = np.random.randn(12)\n",
    "b = np.random.randn(12)\n",
    "a.shape = (1, a.shape[0])\n",
    "#b.shape = (1, b.shape[0])\n",
    "#print(b.shape)\n",
    "c = sparse.hstack((a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用组合算法\n",
    "\n",
    "**随机森林: RandomForestClassifier，RandomForestRegressor**\n",
    "\n",
    "**ExtraTree: ExtraTreesClassifier, ExtraTreesRegressor** (随机森林的改进)\n",
    "\n",
    "**GDBT: GradientBoostingClassifier, GradientBoostingRegressor**\n",
    "\n",
    "**XGB: XGBClassifier, XGBRegressor**(GDBT的改进)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "'''\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "'''\n",
    "data, target = make_blobs(n_samples=10000, n_features=10, centers=100,random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0)\n",
    "\n",
    "# 决策树\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('descisiontree score', clf.score(X_test, y_test))\n",
    "\n",
    "# 随机森林\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('randomforest score', clf.score(X_test, y_test))\n",
    "\n",
    "# extratree\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('extratree score', clf.score(X_test, y_test))\n",
    "\n",
    "'''\n",
    "# GDBT\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('gdbt score', clf.score(X_test, y_test))\n",
    "'''\n",
    "'''\n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('xgb score', clf.score(X_test, y_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降维分解\n",
    "PCA LDA SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
