{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分析常用算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集分为train data, develope data, test data 或（train data, test data）\n",
    "\n",
    "train data 用于模型的训练，其他用于模型的评估\n",
    "模型在训练集和测试集上的结果可以反映拟合情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 分类问题一般用StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "StratifiedKFold(n_splits=2, random_state=1, shuffle=True)\n",
      "TRAIN: [  0   1   4   5   6   7   8   9  10  11  12  14  15  16  18  20  25  28\n",
      "  30  33  34  37  43  44  47  50  53  54  56  57  58  59  62  65  66  68\n",
      "  71  72  73  74  75  76  82  84  85  91  94  95  98  99 100 102 104 106\n",
      " 107 108 110 111 112 113 116 118 120 121 125 127 128 130 139 140 141 144\n",
      " 147 148 149] TEST: [  2   3  13  17  19  21  22  23  24  26  27  29  31  32  35  36  38  39\n",
      "  40  41  42  45  46  48  49  51  52  55  60  61  63  64  67  69  70  77\n",
      "  78  79  80  81  83  86  87  88  89  90  92  93  96  97 101 103 105 109\n",
      " 114 115 117 119 122 123 124 126 129 131 132 133 134 135 136 137 138 142\n",
      " 143 145 146]\n",
      "TRAIN: [  2   3  13  17  19  21  22  23  24  26  27  29  31  32  35  36  38  39\n",
      "  40  41  42  45  46  48  49  51  52  55  60  61  63  64  67  69  70  77\n",
      "  78  79  80  81  83  86  87  88  89  90  92  93  96  97 101 103 105 109\n",
      " 114 115 117 119 122 123 124 126 129 131 132 133 134 135 136 137 138 142\n",
      " 143 145 146] TEST: [  0   1   4   5   6   7   8   9  10  11  12  14  15  16  18  20  25  28\n",
      "  30  33  34  37  43  44  47  50  53  54  56  57  58  59  62  65  66  68\n",
      "  71  72  73  74  75  76  82  84  85  91  94  95  98  99 100 102 104 106\n",
      " 107 108 110 111 112 113 116 118 120 121 125 127 128 130 139 140 141 144\n",
      " 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=1)\n",
    "print(skf.get_n_splits(data, target))\n",
    "print(skf)\n",
    "for train_idx, test_idx in skf.split(data, target):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    X_train, X_test = data[train_idx], data[test_idx]\n",
    "    y_train, y_test = target[train_idx], target[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归问题一般用KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "KFold(n_splits=2, random_state=1, shuffle=True)\n",
      "TRAIN: [  0   1   3   7   8   9  10  13  15  20  21  22  23  24  25  26  27  30\n",
      "  32  34  37  38  41  43  47  49  50  52  57  60  61  63  64  67  68  70\n",
      "  71  72  74  76  79  80  81  82  83  86  87  88  89  93  96  97 100 101\n",
      " 105 106 109 111 115 116 121 124 129 130 133 134 136 137 140 142 143 145\n",
      " 147 148 149] TEST: [  2   4   5   6  11  12  14  16  17  18  19  28  29  31  33  35  36  39\n",
      "  40  42  44  45  46  48  51  53  54  55  56  58  59  62  65  66  69  73\n",
      "  75  77  78  84  85  90  91  92  94  95  98  99 102 103 104 107 108 110\n",
      " 112 113 114 117 118 119 120 122 123 125 126 127 128 131 132 135 138 139\n",
      " 141 144 146]\n",
      "TRAIN: [  2   4   5   6  11  12  14  16  17  18  19  28  29  31  33  35  36  39\n",
      "  40  42  44  45  46  48  51  53  54  55  56  58  59  62  65  66  69  73\n",
      "  75  77  78  84  85  90  91  92  94  95  98  99 102 103 104 107 108 110\n",
      " 112 113 114 117 118 119 120 122 123 125 126 127 128 131 132 135 138 139\n",
      " 141 144 146] TEST: [  0   1   3   7   8   9  10  13  15  20  21  22  23  24  25  26  27  30\n",
      "  32  34  37  38  41  43  47  49  50  52  57  60  61  63  64  67  68  70\n",
      "  71  72  74  76  79  80  81  82  83  86  87  88  89  93  96  97 100 101\n",
      " 105 106 109 111 115 116 121 124 129 130 133 134 136 137 140 142 143 145\n",
      " 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "skf = KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "print(skf.get_n_splits(data, target))\n",
    "print(skf)\n",
    "for train_idx, test_idx in skf.split(data, target):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    X_train, X_test = data[train_idx], data[test_idx]\n",
    "    y_train, y_test = target[train_idx], target[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.preprocessing LabelEncoder , OneHotEncoder ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 组合数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果数据是稠密的可以用numpy的hstack，如果数据是系数的可以用scipy sparse的hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hstack [1 2 3 2 3 4]\n",
      "vstack [[1 2 3]\n",
      " [2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "# numpy.hstack()\n",
    "# 等价于np.concatenate(tup, axis=1)\n",
    "# numpy.vstack()\n",
    "# 等价于np.concatenate(tup, axis=0)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 3, 4])\n",
    "\n",
    "c = np.hstack((a, b))\n",
    "print('hstack', c)\n",
    "c = np.vstack((a, b))\n",
    "print('vstack', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "a = np.random.randn(12)\n",
    "b = np.random.randn(12)\n",
    "a.shape = (1, a.shape[0])\n",
    "#b.shape = (1, b.shape[0])\n",
    "#print(b.shape)\n",
    "c = sparse.hstack((a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用组合算法\n",
    "\n",
    "**随机森林: RandomForestClassifier，RandomForestRegressor**\n",
    "\n",
    "**ExtraTree: ExtraTreesClassifier, ExtraTreesRegressor** (随机森林的改进)\n",
    "\n",
    "**GDBT: GradientBoostingClassifier, GradientBoostingRegressor**\n",
    "\n",
    "**XGB: XGBClassifier, XGBRegressor**(GDBT的改进)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descisiontree score 0.978333333333\n",
      "randomforest score 1.0\n",
      "extratree score 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport xgboost as xgb\\nclf = xgb.XGBClassifier()\\nclf.fit(X_train, y_train)\\nprint('xgb score', clf.score(X_test, y_test))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "'''\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "'''\n",
    "data, target = make_blobs(n_samples=10000, n_features=10, centers=100,random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3, random_state=0)\n",
    "\n",
    "# 决策树\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('descisiontree score', clf.score(X_test, y_test))\n",
    "\n",
    "# 随机森林\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('randomforest score', clf.score(X_test, y_test))\n",
    "\n",
    "# extratree\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('extratree score', clf.score(X_test, y_test))\n",
    "\n",
    "'''\n",
    "# GDBT\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('gdbt score', clf.score(X_test, y_test))\n",
    "'''\n",
    "'''\n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print('xgb score', clf.score(X_test, y_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降维分解\n",
    "PCA LDA SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.86021505  0.87096774  0.86170213  0.82978723  0.82105263  0.82105263\n",
      "   0.81052632  0.82105263  0.82105263  0.82291667]\n",
      " [ 0.84946237  0.87096774  0.85106383  0.85106383  0.83157895  0.85263158\n",
      "   0.83157895  0.84210526  0.84210526  0.84375   ]\n",
      " [ 0.86021505  0.87096774  0.86170213  0.86170213  0.85263158  0.87368421\n",
      "   0.86315789  0.87368421  0.86315789  0.85416667]\n",
      " [ 0.90322581  0.89247312  0.88297872  0.90425532  0.88421053  0.89473684\n",
      "   0.89473684  0.89473684  0.89473684  0.89583333]\n",
      " [ 0.91397849  0.93548387  0.89361702  0.92553191  0.90526316  0.90526316\n",
      "   0.90526316  0.91578947  0.91578947  0.90625   ]\n",
      " [ 0.89247312  0.91397849  0.89361702  0.93617021  0.91578947  0.91578947\n",
      "   0.90526316  0.93684211  0.92631579  0.90625   ]]\n",
      "[[ 0.83333333  0.75        0.90909091  0.81818182  0.8         0.8         0.9\n",
      "   0.8         0.8         0.77777778]\n",
      " [ 0.83333333  0.75        0.90909091  0.90909091  1.          0.8         0.9\n",
      "   0.8         0.8         0.88888889]\n",
      " [ 0.83333333  0.75        0.81818182  0.90909091  1.          0.8         0.9\n",
      "   0.8         0.9         0.88888889]\n",
      " [ 0.83333333  0.83333333  0.90909091  0.81818182  1.          0.9         0.9\n",
      "   0.8         0.9         0.88888889]\n",
      " [ 0.83333333  0.83333333  0.90909091  0.81818182  1.          0.9         0.9\n",
      "   0.8         0.9         1.        ]\n",
      " [ 0.91666667  0.83333333  0.90909091  0.81818182  1.          1.          0.9\n",
      "   0.8         1.          0.88888889]]\n",
      "best_score>  0.895238095238\n",
      "best_params>  {'clf__C': 10.0}\n",
      "accuracy 0.911111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import validation_curve, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "pipl = Pipeline([('scl', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', LinearSVC())])\n",
    "train_scores, test_scores = validation_curve(estimator=pipl, X=X_train, y=y_train, param_name='clf__C', param_range=[0.001, 0.01, 0.1, 1, 10, 100], cv=10) # 十折\n",
    "print(train_scores)\n",
    "print(test_scores)\n",
    "\n",
    "param_grid = [\n",
    "    {'clf__C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0], }\n",
    "]\n",
    "gs = GridSearchCV(estimator=pipl, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print('best_score> ', gs.best_score_)\n",
    "print('best_params> ', gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "accu = clf.score(X_test, y_test)\n",
    "print('accuracy', accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
